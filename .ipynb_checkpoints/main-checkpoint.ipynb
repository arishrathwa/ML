{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import multivariate_normal \n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tabulate import tabulate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.a. Generate a bi-variate normal distribution assuming a two dimensional random vector. Accept the values\n",
    "of parameters required to generate it from the user. Plot the distribution obtained also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_normal_2d(mean1=5,mean2=30,var1=1,var2=20,covariance=-1,size=1000):\n",
    "\tmean = [mean1, mean2]\n",
    "\tcovar = [[var1,covariance],[covariance,var2]]\n",
    "\treturn multivariate_normal(mean,covar,size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.b. Create a random sample set (S1) of 800 size from this distribution and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean1 = float(input(\"Enter the Mean of DIM1, μ1 : \"))\n",
    "# var1 = float(input(\"Enter the Standard Deviation of DIM1, σ2 : \"))\n",
    "# mean2 = float(input(\"Enter the Mean of DIM2, μ2 : \"))\n",
    "# var2 = float(input(\"Enter the Standard Deviation of DIM2, σ1 : \"))\n",
    "# size = int(input(\"Enter the number of points to be generated : \"))\n",
    "\n",
    "mean1 = 30\n",
    "var1 = 15\n",
    "mean2 = 5\n",
    "var2 = 2\n",
    "size = 800\n",
    "\n",
    "df = gen_normal_2d(mean1,mean2,var1,var2,size=size)\n",
    "\n",
    "x = [int(item[0]) for item in df]\n",
    "y = [int(item[1]) for item in df]\n",
    "\n",
    "x = Counter(x)\n",
    "y = Counter(y)\n",
    "\n",
    "x = [[value,x[value]] for value in x]\n",
    "y = [[value,y[value]] for value in y]\n",
    "\n",
    "\n",
    "# plotting data \n",
    "from matplotlib import pyplot as plot\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_gridspec(2,2)\n",
    "\n",
    "subplot_0_01 = fig.add_subplot(ax[0,:])\n",
    "subplot_0_01.scatter([item[0] for item in df],[item[1] for item in df],color='green')\n",
    "subplot_0_01.set_xlabel(\"DIM1 : (μ=%d,σ=%d)\"%(mean1,var1))\n",
    "subplot_0_01.set_ylabel(\"DIM2 : (μ=%d,σ=%d)\"%(mean2,var2))\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.c. For the sample obtained, what would be size of the required hypothesis class for a maximum error of 0.0,\n",
    "0.05, 0.1, 0.3, 0.5, 0.8 and 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_size(epsilon, delta, VC_dim):\n",
    "    return 1/epsilon * (4 * np.log2(2/delta) + 8 * VC_dim * np.log2(13/epsilon))\n",
    "\n",
    "VC_dim = 10\n",
    "delta = 0.05\n",
    "max_errors = [0.05, 0.1, 0.3, 0.5, 0.8, 1.0]\n",
    "\n",
    "for error in max_errors:\n",
    "    sample_size = calculate_sample_size(error, delta, VC_dim)\n",
    "    print(f\"For maximum error {error}: Sample size required = {sample_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.a. Divide the sample set into a train set and test set using the 80:20 method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1 = 5\n",
    "var1 = 1\n",
    "mean2 = 30\n",
    "var2 =20\n",
    "data = gen_normal_2d(mean1=mean1, mean2=mean2, var1=var1, var2=var2, size=800)\n",
    "train_data, test_data = train_test_split(data,test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.b. Generate a linear regression model using the train set, plot the model obtained and report the error in\n",
    "prediction for both the train and test set. Give the parametric form of the model also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# formula used : \n",
    "#     ♦ b₁ = (nΣxᵢyᵢ-ΣxᵢΣyᵢ)/(nΣxᵢ²-(Σxᵢ)²) \n",
    "#     ♦ b₀ = (Σyᵢ-b₁Σxᵢ)/n\n",
    "\n",
    "df_train = pd.DataFrame(train_data,columns=['x','y'])\n",
    "\n",
    "n = len(df_train)\n",
    "sum_x = sum(df_train['x'])\n",
    "sum_y = sum(df_train['y'])\n",
    "sum_xy = sum(df_train['x']*df_train['y'])\n",
    "sum_x2 = sum(df_train['x']*df_train['x'])\n",
    "b1 = (n*sum_xy-sum_x*sum_y)/(n*sum_x2-sum_x**2)\n",
    "b0 = (sum_y-b1*sum_x)/n\n",
    "\n",
    "df_train['predicted'] = b0+b1*df_train['x']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(df_train['x'],df_train['y'],s=2)\n",
    "plt.title(\"Linear Regression\")\n",
    "plt.xlabel(\"Distribution of DIM1 (μ=%d,σ=%d)\"%(mean1,var1))\n",
    "plt.ylabel(\"Distribution of DIM2 (μ=%d,σ=%d)\"%(mean2,var2))\n",
    "train_error = sum((df_train['y']-df_train['predicted'])**2)/n\n",
    "df_test = pd.DataFrame(test_data,columns=['x','y'])\n",
    "df_test['predicted'] = b0+b1*df_test['x']\n",
    "test_error = sum((df_test['y']-df_test['predicted'])**2)/len(df_test)\n",
    "plt.plot(\n",
    "    df_train['x'],df_train['predicted'],color='red',lw=1,\n",
    "    label='y=%.2f+%.2fx, Train MSE =%.2f, Test MSE=%.2f'%(b0,b1,train_error,test_error)\n",
    ")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.c. Randomly select 700 points from the 800 sample set obtained in Q1.b and assign ”C1” as their class label\n",
    "and let ”C2” be the class label for the remaining 100 points. Plot C1 and C2 classes. Combine these points into\n",
    "a new sample set S2 of size 800."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2c \n",
    "mean1 = 5\n",
    "var1 = 1\n",
    "mean2 = 30\n",
    "var2 =20\n",
    "data = gen_normal_2d(mean1=mean1, mean2=mean2, var1=var1, var2=var2, size=800)\n",
    "data = pd.DataFrame(data,columns=['x','y'])\n",
    "df_c1, df_c2 = train_test_split(data,test_size=(100/800))\n",
    "\n",
    "df_c1['class'] = 0\n",
    "df_c2['class'] = 1\n",
    "\n",
    "plt.scatter(df_c1['x'],df_c1['y'],color='green',s=5,label='Class 1')\n",
    "plt.scatter(df_c2['x'],df_c2['y'],color='orange',s=5,label='Class 2')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "df = pd.concat([df_c1, df_c2])\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.d. Create a train set of size 600 by randomly sampling S2 and let the remaining 200 samples make the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "\n",
    "# ## code to avoid class imbalance\n",
    "\n",
    "def get_600():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df[['x','y']],df[['class']],test_size=(200/800),stratify=df[['class']])\n",
    "    \n",
    "    train_df = pd.concat([x_train,y_train],axis=1)\n",
    "    test_df = pd.concat([x_test,y_test],axis=1)\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = to_categorical(y_train)\n",
    "    \n",
    "    x_test = np.array(x_test)\n",
    "    y_test = to_categorical(y_test)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test, train_df, test_df\n",
    "\n",
    "x_train, x_test, y_train, y_test, train_df, test_df = get_600()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a multi-layer perceptron model to classify the C1 and C2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ann():\n",
    "    ann = Sequential()\n",
    "    ann.add(Input((2,)))\n",
    "    ann.add(BatchNormalization())\n",
    "    ann.add(Dense(units=4,activation='relu'))\n",
    "    ann.add(BatchNormalization())\n",
    "    ann.add(Dense(units=2,activation='softmax'))\n",
    "    return ann\n",
    "\n",
    "ann = get_ann()\n",
    "ann.compile(optimizer=SGD(learning_rate=0.01),loss='binary_crossentropy', metrics=['accuracy', 'precision','recall','f1_score'])\n",
    "ann.fit(x_train,y_train,epochs=EPOCHS,verbose=0)\n",
    "\n",
    "ann.evaluate(x_train,y_train)\n",
    "ann.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the confusion matrix, accuracy, precision, recall and F1-score, Give the parametric form of the model obtained also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann.predict(x_test)\n",
    "test_df['predict'] = [0 if item[0]>item[1] else 1 for item in y_pred]\n",
    "c_matrix = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            len(test_df[(test_df['class']==test_df['predict']) & (test_df['predict']==0)]),\n",
    "            len(test_df[(test_df['class']!=test_df['predict']) & (test_df['class']==1) & (test_df['predict']==0)]),\n",
    "        ],\n",
    "        [\n",
    "            len(test_df[(test_df['class']!=test_df['predict']) & (test_df['class']==0) & (test_df['predict']==1)]),\n",
    "            len(test_df[(test_df['class']==test_df['predict']) & (test_df['predict']==1)]),\n",
    "        ]\n",
    "    ],\n",
    "    columns=['Actual0','Actual1'],\n",
    "    index=['Predict0','Predict1'])\n",
    "\n",
    "tp = c_matrix.loc['Predict0','Actual0']\n",
    "tn = c_matrix.loc['Predict1','Actual1']\n",
    "fp = c_matrix.loc['Predict0','Actual1']\n",
    "fn = c_matrix.loc['Predict1','Actual0']\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "precision = (tp/(tp+fp))\n",
    "recall = (tp/(tp+fn))\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "print ('PARAMETRIC FORM')\n",
    "ann.summary()\n",
    "print ('METRICES')\n",
    "print ('CONFUSION MATRIX')\n",
    "print (tabulate(c_matrix,headers='keys',tablefmt='psql'))\n",
    "print (\"Accuracy=%.2f, Precision=%.2f, Recall=%.2f, F1 Score=%.2f\"%(accuracy,precision,recall,f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the ROC curve and report the AUC value also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_df['class']\n",
    "y_pred = ann.predict(x_test)\n",
    "y_pred = [0 if item[0]>item[1] else 1 for item in y_pred]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "o_fpr, o_tpr, _ = roc_curve(y_true, y_true)\n",
    "o_roc_auc = auc(o_fpr,o_tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = %0.2f) (model)' % roc_auc)\n",
    "plt.plot(o_fpr, o_tpr, color='green', lw=2, label='ROC curve (area = %0.2f) (optimal)' % o_roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.e. Carry out a k-fold stratied cross validation and report the various performance metric values for the same number of train and test set samples. Compare these values with that obtained in Q2.d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2e\n",
    "\n",
    "k_folds = 5\n",
    "\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "x_train = train_df[['x','y']]\n",
    "y_train = train_df['class']\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(x_train,y_train):\n",
    "    \n",
    "    x_train_fold = np.array(x_train.iloc[train_index])\n",
    "    x_test_fold = np.array(x_train.iloc[test_index])\n",
    "\n",
    "    y_train_fold = to_categorical(y_train.iloc[train_index])\n",
    "    y_test_fold = to_categorical(y_train.iloc[test_index])\n",
    "\n",
    "    ann = get_ann()\n",
    "    ann.compile(optimizer=SGD(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy', 'precision','recall','f1_score'])\n",
    "\n",
    "    ann.fit(x_train_fold, y_train_fold, epochs=EPOCHS, verbose=0)\n",
    "    ann.evaluate(x_test_fold, y_test_fold)\n",
    "\n",
    "    print (len(ann.get_weights()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.a. For the above model, plot the loss function against any one of the weights from input-to-hidden edges\n",
    "and any one of the weights from hidden-to-output edges. Apply 5 dierent learning rates and compare the loss\n",
    "plots obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3a\n",
    "learning_rates = [1.0, 0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "for rate in learning_rates:\n",
    "    \n",
    "    ann = get_ann()\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint('./weights/_r_%.4f_e_{epoch:02d}.weights.h5'%(rate), save_weights_only=True)\n",
    "    ann.compile(\n",
    "        optimizer=SGD(learning_rate=rate), \n",
    "        loss='binary_crossentropy', \n",
    "        metrics=['accuracy', 'precision','recall','f1_score']\n",
    "    )\n",
    "    \n",
    "    history = ann.fit(x_train_fold, y_train_fold, epochs=EPOCHS, verbose=0, callbacks=[checkpoint_callback])\n",
    "    ann.evaluate(x_test_fold, y_test_fold)\n",
    "    loss_per_epoch = history.history['loss']\n",
    "    plot_data = {\n",
    "        'y' : loss_per_epoch,\n",
    "        'input_to_hidden' : [],\n",
    "        'hidden_to_output' : []\n",
    "    }\n",
    "    for e in range(1,len(loss_per_epoch)+1) :\n",
    "        filename = './weights/_r_%.4f_e_%02d.weights.h5'%(rate,e)\n",
    "        ann.load_weights(filename)\n",
    "        temp = ann.get_weights()\n",
    "        plot_data['input_to_hidden'].append(temp[0][0])\n",
    "        plot_data['hidden_to_output'].append(temp[-1][0])\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,4))\n",
    "\n",
    "    ax = fig.add_gridspec(1,2)\n",
    "\n",
    "    subplot_0_0 = fig.add_subplot(ax[0,0])\n",
    "    subplot_0_0.scatter(plot_data['input_to_hidden'],plot_data['y'],color='red',s=3)\n",
    "    subplot_0_0.set_xlabel(\"Weight (Input ot Hidden)\")\n",
    "    subplot_0_0.set_ylabel(\"Loss\")\n",
    "    if plot_data['input_to_hidden'][0]>plot_data['input_to_hidden'][-1] :\n",
    "        subplot_0_0.invert_xaxis()   \n",
    "    subplot_0_0.set_xticklabels(plot_data['input_to_hidden'],rotation=45)\n",
    "\n",
    "    subplot_0_1 = fig.add_subplot(ax[0,1])\n",
    "    subplot_0_1.scatter(plot_data['hidden_to_output'],plot_data['y'],color='blue',s=3)\n",
    "    subplot_0_1.set_xlabel(\"Weight (Hidden to Output)\")\n",
    "    subplot_0_1.set_ylabel(\"Loss\")\n",
    "    if plot_data['hidden_to_output'][0]>plot_data['hidden_to_output'][-1] :\n",
    "        subplot_0_1.invert_xaxis()\n",
    "        \n",
    "    subplot_0_1.set_xticklabels(plot_data['hidden_to_output'],rotation=45)\n",
    "   \n",
    "    plt.title('Learning Rate =%.4f'%(rate))\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.b. Repeat Q2.d. for two more different random initialization of weights and compare the results obtained\n",
    "with that obtained in Q2.d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, train_df, test_df = get_600()\n",
    "\n",
    "for _ in range (5):\n",
    "    \n",
    "    ann = get_ann()\n",
    "    ann.compile(optimizer=SGD(learning_rate=0.01),loss='binary_crossentropy', metrics=['accuracy', 'precision','recall','f1_score'])\n",
    "    \n",
    "    print ('WEIGHTS')\n",
    "    for layer in ann.layers:\n",
    "        print (layer.name)\n",
    "        print (np.array(layer.weights[0]))\n",
    "    print ()\n",
    "    \n",
    "    ann.fit(x_train,y_train,epochs=EPOCHS,verbose=0)\n",
    "    ann.evaluate(x_train,y_train)\n",
    "    ann.evaluate(x_test,y_test)\n",
    "\n",
    "    y_pred = ann.predict(x_test)\n",
    "    test_df['predict'] = [0 if item[0]>item[1] else 1 for item in y_pred]\n",
    "    c_matrix = pd.DataFrame(\n",
    "        [\n",
    "            [\n",
    "                len(test_df[(test_df['class']==test_df['predict']) & (test_df['predict']==0)]),\n",
    "                len(test_df[(test_df['class']!=test_df['predict']) & (test_df['class']==1) & (test_df['predict']==0)]),\n",
    "            ],\n",
    "            [\n",
    "                len(test_df[(test_df['class']!=test_df['predict']) & (test_df['class']==0) & (test_df['predict']==1)]),\n",
    "                len(test_df[(test_df['class']==test_df['predict']) & (test_df['predict']==1)]),\n",
    "            ]\n",
    "        ],\n",
    "        columns=['Actual0','Actual1'],\n",
    "        index=['Predict0','Predict1'])\n",
    "\n",
    "    tp = c_matrix.loc['Predict0','Actual0']\n",
    "    tn = c_matrix.loc['Predict1','Actual1']\n",
    "    fp = c_matrix.loc['Predict0','Actual1']\n",
    "    fn = c_matrix.loc['Predict1','Actual0']\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    precision = (tp/(tp+fp))\n",
    "    recall = (tp/(tp+fn))\n",
    "    f1_score = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "    print ('METRICES')\n",
    "    print ('CONFUSION MATRIX')\n",
    "    print (tabulate(c_matrix,headers='keys',tablefmt='psql'))\n",
    "    print (\"Accuracy=%.2f, Precision=%.2f, Recall=%.2f, F1 Score=%.2f\"%(accuracy,precision,recall,f1_score))\n",
    "    \n",
    "    y_true = test_df['class']\n",
    "    y_pred = ann.predict(x_test)\n",
    "    y_pred = [0 if item[0]>item[1] else 1 for item in y_pred]\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    o_fpr, o_tpr, _ = roc_curve(y_true, y_true)\n",
    "    o_roc_auc = auc(o_fpr,o_tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f) (model)' % roc_auc)\n",
    "    plt.plot(o_fpr, o_tpr, color='red', lw=2, label='ROC curve (area = %0.2f) (optimal)' % o_roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
